{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ad9568",
   "metadata": {},
   "source": [
    "# 02. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4bff30",
   "metadata": {},
   "source": [
    "**Target Metric: F1 Score**\n",
    "\n",
    "**Reason: Imbalanced Label Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8d9c1",
   "metadata": {},
   "source": [
    "## 0. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1751aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 16:07:13.786725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756739233.797885   45037 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756739233.801379   45037 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756739233.811145   45037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756739233.811154   45037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756739233.811155   45037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756739233.811156   45037 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-01 16:07:13.814463: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import platform, subprocess, psutil, torch, transformers, os, logging, warnings, json, yaml\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments,              #type: ignore\n",
    "    Trainer,                        #type: ignore\n",
    "    EarlyStoppingCallback,          #type: ignore\n",
    "    get_linear_schedule_with_warmup #type: ignore\n",
    ")\n",
    "\n",
    "# ----------------------------------- SETUP ---------------------------------- #\n",
    "\n",
    "# Load configuration\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# matplotlib inline setup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60291bf7",
   "metadata": {},
   "source": [
    "## 1. System Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c4efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Linux 6.8.0-65-generic\n",
      "Python version: 3.10.12\n",
      "Architecture: x86_64\n",
      "Total RAM: 31.2 GB\n",
      "Available RAM: 21.7 GB\n",
      "RAM Usage: 30.5%\n",
      "Total Disk: 419.7 GB\n",
      "Free Disk: 316.1 GB\n",
      "GPU CHECK\n",
      "✓ NVIDIA GPU detected\n",
      "GPU: |   0  NVIDIA GeForce RTX 3070 Ti     On  |   00000000:07:00.0  On |                  N/A |\n",
      "PyTorch version: 2.7.1+cu126\n",
      "✓ CUDA available: 12.6\n",
      "✓ GPU count: 1\n",
      "  GPU 0: NVIDIA GeForce RTX 3070 Ti (7.7 GB)\n",
      "TensorFlow version: 2.19.0\n",
      "✓ TensorFlow GPU support: 1 GPU(s)\n",
      "  GPU 0: /physical_device:GPU:0\n",
      "Transformers version: 4.54.1\n",
      "\n",
      "RECOMMENDATIONS\n",
      "TIP: GPU has limited memory - use smaller batch sizes and gradient accumulation\n",
      "\n",
      "System constraints check complete\n",
      "\n",
      "GPU ACTIVATION\n",
      "GPU activated: NVIDIA GeForce RTX 3070 Ti\n",
      "  Device: cuda\n",
      "  Memory allocated: 0.00 GB\n",
      "  Memory reserved: 0.00 GB\n",
      "  GPU cache cleared\n",
      "Training device set to: cuda\n"
     ]
    }
   ],
   "source": [
    "def check_system_constraints():\n",
    "    \"\"\"Check system resources and constraints for model training\"\"\"\n",
    "    \n",
    "    # Basic system info\n",
    "    print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Python version: {platform.python_version()}\")\n",
    "    print(f\"Architecture: {platform.machine()}\")\n",
    "    \n",
    "    # Check available memory\n",
    "    try:\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"Total RAM: {memory.total / (1024**3):.1f} GB\")\n",
    "        print(f\"Available RAM: {memory.available / (1024**3):.1f} GB\")\n",
    "        print(f\"RAM Usage: {memory.percent}%\")\n",
    "        \n",
    "        # Disk space\n",
    "        disk = psutil.disk_usage('/')\n",
    "        print(f\"Total Disk: {disk.total / (1024**3):.1f} GB\")\n",
    "        print(f\"Free Disk: {disk.free / (1024**3):.1f} GB\")\n",
    "    except ImportError:\n",
    "        print(\"psutil not installed - install with: pip install psutil\")\n",
    "    \n",
    "    # Check CUDA/GPU availability\n",
    "    print(\"GPU CHECK\")\n",
    "    \n",
    "    # Check NVIDIA GPU\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ NVIDIA GPU detected\")\n",
    "            # Extract basic GPU info\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'Tesla' in line or 'GeForce' in line or 'Quadro' in line or 'RTX' in line or 'GTX' in line:\n",
    "                    print(f\"GPU: {line.strip()}\")\n",
    "        else:\n",
    "            print(\"✗ NVIDIA GPU not detected or nvidia-smi not available\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ nvidia-smi not found\")\n",
    "    \n",
    "    # Check PyTorch GPU support\n",
    "    try:\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"✓ CUDA available: {torch.version.cuda}\")   #type: ignore\n",
    "            print(f\"✓ GPU count: {torch.cuda.device_count()}\")\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                props = torch.cuda.get_device_properties(i)\n",
    "                print(f\"  GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f} GB)\")\n",
    "        else:\n",
    "            print(\"✗ CUDA not available in PyTorch\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not installed\")\n",
    "    \n",
    "    # Check TensorFlow GPU support\n",
    "    try:\n",
    "        print(f\"TensorFlow version: {tf.__version__}\")\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            print(f\"✓ TensorFlow GPU support: {len(gpus)} GPU(s)\")\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                print(f\"  GPU {i}: {gpu.name}\")\n",
    "        else:\n",
    "            print(\"✗ No GPU support in TensorFlow\")\n",
    "    except ImportError:\n",
    "        print(\"TensorFlow not installed\")\n",
    "    \n",
    "    # Check transformers library\n",
    "    try:\n",
    "        print(f\"Transformers version: {transformers.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"Transformers library not installed\")\n",
    "        \n",
    "    print(\"\\nRECOMMENDATIONS\")\n",
    "    \n",
    "    # Memory recommendations\n",
    "    try:\n",
    "        if memory.available / (1024**3) < 8:    #type: ignore\n",
    "            print(\"WARNING: Less than 8GB RAM available\")\n",
    "            print(\"   Consider closing other applications or using smaller batch sizes\")\n",
    "        \n",
    "        if disk.free / (1024**3) < 10:          #type: ignore\n",
    "            print(\"WARNING: Less than 10GB disk space available\")\n",
    "            print(\"   Model checkpoints and datasets may require significant space\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # GPU recommendations\n",
    "    try:\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"TIP: Training will use CPU only - consider using Google Colab or cloud GPU\")\n",
    "        elif torch.cuda.device_count() == 1:\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            if props.total_memory < 8 * 1024**3:  # Less than 8GB VRAM\n",
    "                print(\"TIP: GPU has limited memory - use smaller batch sizes and gradient accumulation\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"\\nSystem constraints check complete\")\n",
    "    \n",
    "    # Return device information for use in training\n",
    "    return {\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "        'memory_gb': memory.available / (1024**3) if 'memory' in locals() else None #type: ignore\n",
    "    }\n",
    "\n",
    "# Run the check and get system info\n",
    "system_info = check_system_constraints()\n",
    "\n",
    "# ------------------------------ GPU ACTIVATION ------------------------------ #\n",
    "print(\"\\nGPU ACTIVATION\")\n",
    "\n",
    "# Set up device for PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU activated: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Memory allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Memory reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Set memory allocation strategy (optional)\n",
    "    torch.cuda.empty_cache()  # Clear cache\n",
    "    print(\"  GPU cache cleared\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU for training\")\n",
    "    print(f\"  Device: {device}\")\n",
    "\n",
    "print(f\"Training device set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c914ee",
   "metadata": {},
   "source": [
    "## 2. Load Training, Validation, and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b016bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3232, Val set size: 693, Test set size: 693\n",
      "\n",
      "Train \n",
      "                                                 text  label\n",
      "0  The contract covers new energy-efficient AC dr...      1\n",
      "1  The cranes would be installed onboard two frei...      1\n",
      "2  Inca Contract Manufacturing will carry out the...      1\n",
      "3  Finnish metal components supplier Component AY...      2\n",
      "4  ` Low energy consumption and flexible loading ...      1\n",
      "\n",
      "Validation \n",
      "                                                 text  label\n",
      "0  Concord would focus on the development, manufa...      1\n",
      "1  Why put up costly cell phone towers in thinly ...      1\n",
      "2  Forum needs a clear signal of commitment from ...      1\n",
      "3  TomTom has given assurances that it will conti...      2\n",
      "4  The company said it observed a current stabili...      2\n",
      "\n",
      "Test \n",
      "                                                 text  label\n",
      "0  The Swedish player became majority owner of Ce...      1\n",
      "1  Ruukki's order book at the end of 2010 was 30%...      2\n",
      "2  Operating profit improved by 39.9% to EUR 18.0...      2\n",
      "3  The contractor of the shopping center, China S...      1\n",
      "4  Chapman, the Stockholm-headquartered private e...      1\n"
     ]
    }
   ],
   "source": [
    "train, val, test = config['data']['train_data'], config['data']['val_data'], config['data']['test_data']\n",
    "\n",
    "train, val, test = pd.read_csv(train), pd.read_csv(val), pd.read_csv(test)\n",
    "\n",
    "print(f\"Train set size: {len(train)}, Val set size: {len(val)}, Test set size: {len(test)}\")\n",
    "print(\"\")\n",
    "print(f\"Train \\n {train.head()}\")\n",
    "print(\"\")\n",
    "print(f\"Validation \\n {val.head()}\")\n",
    "print(\"\")\n",
    "print(f\"Test \\n {test.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67876129",
   "metadata": {},
   "source": [
    "## 3. Load Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df5a14",
   "metadata": {},
   "source": [
    "### 3.1 Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b3986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ LOAD METADATA ------------------------------ #\n",
    "metadata = config['data']['metadata']\n",
    "with open(metadata, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "print(\"Metadata loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b9774",
   "metadata": {},
   "source": [
    "### 3.2 Display Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8425539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "   Total samples: 4,618\n",
      "   Number of classes: 3\n",
      "   Class names: ['negative', 'positive', 'neutral']\n",
      "   Processing date: 2025-08-09T17:27:36.071920\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ DISPLAY DATASET INFORMATION ----------------------- #\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"   Total samples: {metadata['dataset_info']['total_samples']:,}\")\n",
    "print(f\"   Number of classes: {metadata['dataset_info']['num_classes']}\")\n",
    "print(f\"   Class names: {metadata['dataset_info']['class_names']}\")\n",
    "print(f\"   Processing date: {metadata['dataset_info']['processing_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09874811",
   "metadata": {},
   "source": [
    "### 3.3 Display Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c484d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Splits:\n",
      "   Train: 3,232 samples (70.0%)\n",
      "   Val: 693 samples (15.0%)\n",
      "   Test: 693 samples (15.0%)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------- DISPLAY DATA SPLITS --------------------------- #\n",
    "print(f\"\\nData Splits:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if split in metadata['splits']:\n",
    "        size = metadata['splits'][split]['size']\n",
    "        pct = metadata['splits'][split]['percentage']\n",
    "        print(f\"   {split.capitalize()}: {size:,} samples ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9e159",
   "metadata": {},
   "source": [
    "### 3.4 Display Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9af72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Distribution:\n",
      "   Train:\n",
      "      neutral: 1890\n",
      "      positive: 932\n",
      "      negative: 410\n",
      "   Val:\n",
      "      neutral: 405\n",
      "      positive: 200\n",
      "      negative: 88\n",
      "   Test:\n",
      "      neutral: 405\n",
      "      positive: 200\n",
      "      negative: 88\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ DISPLAY LABEL DISTRIBUTION ------------------------ #\n",
    "print(f\"\\nLabel Distribution:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if split in metadata['label_distribution']:\n",
    "        print(f\"   {split.capitalize()}:\")\n",
    "        for label, count in metadata['label_distribution'][split].items():\n",
    "            print(f\"      {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eec434",
   "metadata": {},
   "source": [
    "### 3.5 Display Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b7c0c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration:\n",
      "   Tokenizer: ProsusAI/finbert\n",
      "   Max length: 512\n",
      "   Vocab size: 30,522\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ DISPLAY MODEL CONFIGURATION ----------------------- #\n",
    "if 'model_info' in metadata:\n",
    "    print(f\"\\nModel Configuration:\")\n",
    "    print(f\"   Tokenizer: {metadata['model_info']['tokenizer']}\")\n",
    "    print(f\"   Max length: {metadata['model_info']['max_length']}\")\n",
    "    print(f\"   Vocab size: {metadata['model_info']['vocab_size']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a642b",
   "metadata": {},
   "source": [
    "### 3.6 Display Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48163b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text Statistics:\n",
      "   Avg characters: 129.7\n",
      "   Avg words: 21.1\n",
      "   Word range: 7-52 words\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- DISPLAY TEXT STATISTICS ------------------------- #\n",
    "if 'text_statistics' in metadata:\n",
    "    print(f\"\\nText Statistics:\")\n",
    "    print(f\"   Avg characters: {metadata['text_statistics']['avg_char_length']:.1f}\")\n",
    "    print(f\"   Avg words: {metadata['text_statistics']['avg_word_length']:.1f}\")\n",
    "    print(f\"   Word range: {metadata['text_statistics']['min_word_length']}-{metadata['text_statistics']['max_word_length']} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444e019",
   "metadata": {},
   "source": [
    "### 3.7 Display Validation Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674ec6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation Status: PASS\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- DISPLAY VALIDATION STATUS ------------------------ #\n",
    "if 'validation_results' in metadata:\n",
    "    status = metadata['validation_results']['overall_status']\n",
    "    print(f\"\\nData Validation Status: {status}\")\n",
    "    if status != 'PASS':\n",
    "        print(\"   Some validation issues detected - check preprocessing notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7d290",
   "metadata": {},
   "source": [
    "## 4. Load Label Encoder Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a5fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class weights: {0: 2.626848691695108, 1: 0.5701234567901234, 2: 1.1556556556556556}\n",
      "   Number of classes: 3\n",
      "   Class names: ['negative', 'positive', 'neutral']\n",
      "   Max sequence length: 512\n",
      "   Tokenizer: ProsusAI/finbert\n"
     ]
    }
   ],
   "source": [
    "artifact_path = config['data'].get('label_encoder')\n",
    "label_to_id = {}\n",
    "id_to_label = {}\n",
    "class_weights = None\n",
    "\n",
    "# Try to load label-encoder artifact (preferred source)\n",
    "if artifact_path and Path(artifact_path).exists():\n",
    "    with open(artifact_path, 'r') as f:\n",
    "        le_data = json.load(f)\n",
    "\n",
    "    label_to_id = le_data.get('label_to_id', {})  # label name -> id\n",
    "    raw_id_to_label = le_data.get('id_to_label', {})  # keys may be strings\n",
    "    id_to_label = {int(k): v for k, v in raw_id_to_label.items()} if raw_id_to_label else {}\n",
    "\n",
    "    # Normalize class_weights from artifact: keys may be string ids or label names\n",
    "    raw_class_weights = le_data.get('class_weights') or {}\n",
    "    cw = {}\n",
    "    for k, v in raw_class_weights.items():\n",
    "        try:\n",
    "            key_int = int(k)\n",
    "            cw[key_int] = float(v)\n",
    "        except ValueError:\n",
    "            # key is label name -> map via label_to_id if possible\n",
    "            if label_to_id and k in label_to_id:\n",
    "                cw[label_to_id[k]] = float(v)\n",
    "    if cw:\n",
    "        class_weights = cw\n",
    "\n",
    "# If no usable class_weights from artifact, try metadata\n",
    "if class_weights is None:\n",
    "    ld = metadata.get('label_distribution', {})\n",
    "    if 'class_weights' in ld:\n",
    "        raw = ld['class_weights']\n",
    "        cw = {}\n",
    "        for k, v in raw.items():\n",
    "            try:\n",
    "                key_int = int(k)\n",
    "                cw[key_int] = float(v)\n",
    "            except ValueError:\n",
    "                if label_to_id and k in label_to_id:\n",
    "                    cw[label_to_id[k]] = float(v)\n",
    "        if cw:\n",
    "            class_weights = cw\n",
    "    elif 'overall' in ld:\n",
    "        overall_dist = ld['overall']\n",
    "        print(f\"   Overall label distribution: {overall_dist}\")\n",
    "        total_samples = sum(overall_dist.values())\n",
    "        num_labels = len(overall_dist)\n",
    "\n",
    "        # mapping: prefer label_to_id (artifact), otherwise use metadata class_names order\n",
    "        if label_to_id:\n",
    "            mapping = label_to_id\n",
    "        else:\n",
    "            mapping = {name: i for i, name in enumerate(metadata['dataset_info']['class_names'])}\n",
    "\n",
    "        cw = {}\n",
    "        for label, count in overall_dist.items():\n",
    "            class_id = mapping.get(label)\n",
    "            if class_id is None:\n",
    "                try:\n",
    "                    class_id = int(label)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            cw[class_id] = total_samples / (num_labels * max(1, count))\n",
    "        class_weights = cw\n",
    "\n",
    "# Fallback to equal weights\n",
    "if class_weights is None:\n",
    "    num_classes = metadata['dataset_info']['num_classes']\n",
    "    class_weights = {i: 1.0 for i in range(num_classes)}\n",
    "\n",
    "print(f\"   Class weights: {class_weights}\")\n",
    "\n",
    "# Also extract other useful parameters\n",
    "num_classes = metadata['dataset_info']['num_classes']\n",
    "class_names = metadata['dataset_info']['class_names']\n",
    "max_length = metadata['model_info']['max_length'] if 'model_info' in metadata else 512\n",
    "tokenizer_name = metadata['model_info']['tokenizer'] if 'model_info' in metadata else 'ProsusAI/finbert'\n",
    "\n",
    "print(f\"   Number of classes: {num_classes}\")\n",
    "print(f\"   Class names: {class_names}\")\n",
    "print(f\"   Max sequence length: {max_length}\")\n",
    "print(f\"   Tokenizer: {tokenizer_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320c1d1",
   "metadata": {},
   "source": [
    "## 5. Load FinBERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ffd92af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer directory: ../data/processed/artifacts/finbert_tokenizer\n",
      "FinBERT tokenizer loaded from local dir: ../data/processed/artifacts/finbert_tokenizer\n",
      "  - Vocab size: 30,522\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cfg_tokenizer_path = Path(config['data']['tokenizer'])\n",
    "    tokenizer_dir = cfg_tokenizer_path.parent if cfg_tokenizer_path.is_file() else cfg_tokenizer_path\n",
    "\n",
    "    print(\"Using tokenizer directory:\", tokenizer_dir)\n",
    "    if tokenizer_dir.exists():\n",
    "        finbert_tokenizer = AutoTokenizer.from_pretrained(str(tokenizer_dir), use_fast=True)\n",
    "        print(f\"FinBERT tokenizer loaded from local dir: {tokenizer_dir}\")\n",
    "    else:\n",
    "        finbert_tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)\n",
    "        print(f\"FinBERT tokenizer loaded from hub: {tokenizer_name}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"  - Vocab size: {len(finbert_tokenizer):,}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print(\"Error loading FinBERT tokenizer:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a727324",
   "metadata": {},
   "source": [
    "## 6. Assign Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ccd89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights mapped to labels:\n",
      "  negative: 2.6268\n",
      "  positive: 0.5701\n",
      "  neutral: 1.1557\n",
      "PyTorch class weight tensor: tensor([2.6268, 0.5701, 1.1557])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Ensure required variables exist\n",
    "    assert 'class_weights' in globals() and class_weights is not None\n",
    "\n",
    "    # Build id -> label name mapping (prefer artifact id_to_label, then invert label_to_id, else use class_names)\n",
    "    if id_to_label:\n",
    "        id_to_name = id_to_label\n",
    "    elif label_to_id:\n",
    "        id_to_name = {int(v): k for k, v in label_to_id.items()}\n",
    "    elif class_names:\n",
    "        id_to_name = {i: name for i, name in enumerate(class_names)}\n",
    "    else:\n",
    "        id_to_name = {}\n",
    "\n",
    "    # Map numeric class_weights -> label names\n",
    "    mapped_class_weights = {}\n",
    "    for cid in range(num_classes):\n",
    "        w = float(class_weights.get(cid, 1.0))\n",
    "        name = id_to_name.get(cid, str(cid))\n",
    "        mapped_class_weights[name] = w\n",
    "\n",
    "    # Prepare tensor for PyTorch loss (ordered by class id 0..num_classes-1)\n",
    "    import torch\n",
    "    class_weight_tensor = torch.tensor([float(class_weights.get(i, 1.0)) for i in range(num_classes)], dtype=torch.float)\n",
    "\n",
    "    # Expose variables for downstream cells\n",
    "    print(\"Class weights mapped to labels:\")\n",
    "    for name, w in mapped_class_weights.items():\n",
    "        print(f\"  {name}: {w:.4f}\")\n",
    "    print(f\"PyTorch class weight tensor: {class_weight_tensor}\")\n",
    "except Exception as e:\n",
    "    print(\"Error assigning class weights to labels:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5005e9",
   "metadata": {},
   "source": [
    "## 7. Prepare Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019cef8",
   "metadata": {},
   "source": [
    "### 7.1 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c6035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights applied:\n",
      " negative (id=0): 2.6268\n",
      " positive (id=1): 0.5701\n",
      " neutral (id=2): 1.1557\n",
      "\n",
      "Model Summary:\n",
      " Model: ProsusAI/finbert\n",
      " Classes: 3 (negative, positive, neutral)\n",
      " Total parameters: 109,484,547\n",
      " Trainable parameters: 109,484,547\n",
      " Frozen parameters: 0\n",
      " Model size: ~417.7 MB\n",
      " Device: cuda\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ProsusAI/finbert\"\n",
    "\n",
    "# Load model with proper configuration\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,\n",
    "    problem_type=\"single_label_classification\",\n",
    "    # Add attention and hidden dropout for better regularization\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    hidden_dropout_prob=0.1\n",
    ")\n",
    "\n",
    "# Set label mappings for human-readable output\n",
    "model.config.id2label = {i: name for i, name in enumerate(class_names)}\n",
    "model.config.label2id = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Enhanced dropout configuration\n",
    "if hasattr(model, 'classifier'):\n",
    "    # Add dropout to the classification head if it exists\n",
    "    if hasattr(model.classifier, 'dropout'):\n",
    "        model.classifier.dropout = nn.Dropout(0.15)  # Slightly higher for classification layer\n",
    "    \n",
    "    # If classifier doesn't have dropout, add it before the final layer\n",
    "    elif hasattr(model.classifier, 'dense'):\n",
    "        original_classifier = model.classifier\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.15),\n",
    "            original_classifier\n",
    "        )\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Create weighted loss function using precomputed class weights\n",
    "class_weight_tensor = class_weight_tensor.to(device)  # Move weights to same device as model\n",
    "\n",
    "# Create custom weighted CrossEntropyLoss\n",
    "weighted_loss_fn = nn.CrossEntropyLoss(weight=class_weight_tensor, label_smoothing=0.1)\n",
    "\n",
    "print(f\"Class weights applied:\")\n",
    "for i, (name, weight) in enumerate(zip(class_names, class_weight_tensor.cpu())):\n",
    "    print(f\" {name} (id={i}): {weight:.4f}\")\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\" Model: {model_name}\")\n",
    "print(f\" Classes: {num_classes} ({', '.join(class_names)})\")\n",
    "print(f\" Total parameters: {total_params:,}\")\n",
    "print(f\" Trainable parameters: {trainable_params:,}\")\n",
    "print(f\" Frozen parameters: {frozen_params:,}\")\n",
    "print(f\" Model size: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "print(f\" Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32778e",
   "metadata": {},
   "source": [
    "### 7.2 Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f52260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    \"\"\"Custom trainer with weighted loss for class imbalance\"\"\"\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):    #type: ignore\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        if hasattr(outputs, 'logits'):\n",
    "            logits = outputs.logits\n",
    "        else:\n",
    "            logits = outputs.get(\"logits\") if isinstance(outputs, dict) else outputs[1]\n",
    "        \n",
    "        # Use weighted loss function\n",
    "        loss = weighted_loss_fn(logits, labels)\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e07f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Comprehensive metrics computation:\n",
    "    - Macro-averaged F1, weighted F1, per-class F1\n",
    "    - Precision and recall for each class\n",
    "    - Accuracy for baseline comparison\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    try:\n",
    "        # Core metrics\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
    "        f1_weighted = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
    "        f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
    "        f1_per_class = f1_score(labels, predictions, average=None, zero_division=0)\n",
    "        \n",
    "        # Detailed classification report\n",
    "        report = classification_report(\n",
    "            labels, predictions, \n",
    "            target_names=class_names, \n",
    "            output_dict=True, \n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        # Build comprehensive metrics dictionary\n",
    "        metrics = {\n",
    "            'accuracy': float(accuracy),\n",
    "            'f1_macro': float(f1_macro),        # Primary metric for imbalanced data\n",
    "            'f1_weighted': float(f1_weighted),   # Weighted by support\n",
    "            'f1_micro': float(f1_micro),        # Overall accuracy equivalent\n",
    "        }\n",
    "        \n",
    "        # Add per-class metrics\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            if i < len(f1_per_class):                                                                           #type: ignore\n",
    "                metrics[f'f1_{class_name}'] = float(f1_per_class[i])                                            #type: ignore\n",
    "                metrics[f'precision_{class_name}'] = float(report.get(class_name, {}).get('precision', 0.0))    #type: ignore\n",
    "                metrics[f'recall_{class_name}'] = float(report.get(class_name, {}).get('recall', 0.0))          #type: ignore\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing metrics: {e}\")\n",
    "        return {'accuracy': 0.0, 'f1_macro': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7463a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(predictions, labels, class_names, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot confusion matrix for detailed analysis\"\"\"\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62e644",
   "metadata": {},
   "source": [
    "### 7.3 Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c51159da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Configuration Summary:\n",
      " Batch size: 32 (train) / 64 (eval)\n",
      " Learning rate: 2e-05 (BERT fine-tuning range)\n",
      " Epochs: 4 (BERT recommended)\n",
      " FP16: True\n",
      " Gradient accumulation: 1 steps\n",
      " Primary metric: F1-macro (imbalanced data focus)\n",
      " Eval/Save steps: 200/600\n",
      " Early stopping: 3 patience on F1-macro\n"
     ]
    }
   ],
   "source": [
    "gpu_optimized_batch_size = 32\n",
    "if system_info.get('memory_gb', 0) < 16:\n",
    "    gpu_optimized_batch_size = 24\n",
    "\n",
    "# Gradient accumulation for smaller batch sizes\n",
    "gradient_accumulation_steps = 1\n",
    "if gpu_optimized_batch_size < 32:\n",
    "    gradient_accumulation_steps = 2  # Effective batch size = 24*2 = 48\n",
    "\n",
    "eval_steps = 200\n",
    "save_steps = 600  # Multiple of eval_steps for compatibility\n",
    "\n",
    "# Create optimized training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/finbert_sentiment\",\n",
    "    \n",
    "    num_train_epochs=4,  # Conservative for stability\n",
    "    \n",
    "    # Batch sizes: 16-32 range, optimized for GPU\n",
    "    per_device_train_batch_size=gpu_optimized_batch_size,\n",
    "    per_device_eval_batch_size=gpu_optimized_batch_size * 2,  # Larger for eval\n",
    "    \n",
    "    # Learning rate: 1e-5 to 5e-5 range for BERT\n",
    "    learning_rate=2e-5,  # Sweet spot for FinBERT\n",
    "    \n",
    "    # AdamW optimizer with weight decay (automatically used)\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Gradient accumulation for effective larger batch size\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    max_grad_norm=1.0,  # Gradient clipping\n",
    "    \n",
    "    # Mixed precision training (fp16) for RTX 3070 Ti\n",
    "    fp16=True,\n",
    "    \n",
    "    # Data loading optimization\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    \n",
    "    # Evaluation strategy: steps-based for frequent monitoring\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    \n",
    "    # Save strategy aligned with evaluation\n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=3,  # Keep only best 3 checkpoints\n",
    "    \n",
    "    # Load best model at end based on F1-score\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1_macro\",  # F1-macro for imbalanced data\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    # Monitoring and logging\n",
    "    logging_steps=50,\n",
    "    logging_strategy=\"steps\",\n",
    "    \n",
    "    # Disable external services\n",
    "    report_to=None,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# The Trainer will use get_linear_schedule_with_warmup by default\n",
    "\n",
    "# Early stopping monitoring F1-score\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Configuration Summary:\")\n",
    "print(f\" Batch size: {gpu_optimized_batch_size} (train) / {gpu_optimized_batch_size * 2} (eval)\")\n",
    "print(f\" Learning rate: {training_args.learning_rate} (BERT fine-tuning range)\")\n",
    "print(f\" Epochs: {training_args.num_train_epochs} (BERT recommended)\")\n",
    "print(f\" FP16: {training_args.fp16}\")\n",
    "print(f\" Gradient accumulation: {gradient_accumulation_steps} steps\")\n",
    "print(f\" Primary metric: F1-macro (imbalanced data focus)\")\n",
    "print(f\" Eval/Save steps: {eval_steps}/{save_steps}\")\n",
    "print(f\" Early stopping: 3 patience on F1-macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d47e19",
   "metadata": {},
   "source": [
    "### 7.4 Wrap DataFrame in DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04b82a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: train=3232, val=693, test=693\n"
     ]
    }
   ],
   "source": [
    "class FinSentDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Lightweight Dataset wrapping a pandas DataFrame for Trainer\"\"\"\n",
    "    def __init__(self, df, tokenizer, max_length=512, text_col='text', label_col='label'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_col = text_col\n",
    "        self.label_col = label_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = str(row[self.text_col])\n",
    "        label = int(row[self.label_col])\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Create dataset instances expected by Trainer\n",
    "train_dataset = FinSentDataset(train, finbert_tokenizer, max_length=max_length, text_col='text', label_col='label')\n",
    "val_dataset   = FinSentDataset(val, finbert_tokenizer,   max_length=max_length, text_col='text', label_col='label')\n",
    "test_dataset  = FinSentDataset(test, finbert_tokenizer,  max_length=max_length, text_col='text', label_col='label')\n",
    "\n",
    "print(f\"Datasets: train={len(train_dataset)}, val={len(val_dataset)}, test={len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccf5a6",
   "metadata": {},
   "source": [
    "### 7.5 Initialise Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63ec0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=finbert_tokenizer,\n",
    "    compute_metrics=compute_metrics,  # F1-focused metrics\n",
    "    callbacks=[early_stopping],      # F1-based early stopping\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
